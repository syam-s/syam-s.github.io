<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Career Page">
    <meta name="author" content="Anjith George">

    <title>Anjith George - Homepage</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/1-col-portfolio.css" rel="stylesheet">
    <link href="css/style.css" rel="stylesheet">

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-69511238-1', 'auto');
      ga('send', 'pageview');

    </script>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body>


    <!-- Page Content -->
	<div class="container">
	<center>
			<div class="page-header1">
			<h1 style = "color:#585858"><b>Anjith George</b></h1>
		</div>
	</center>

		<ul class="nav nav-tabs nav-justified">
  		<li role="presentation"><a href="index.html">About</a></li>
  		<li role="presentation" class="active"><a href="#">Research</a></li>
  		<li role="presentation"><a href="resume.html">Curriculum Vitae</a></li>
  		<li role="presentation"><a href="contact.html">Contact</a></li>
      <li role="presentation"><a href="demos.html">Demos</a></li>

		</ul>
    <br><br>
    <!-- Project One -->
     <div class="pubwrap">
  <div class="row">
    <div class="col-md-6">
      <div class="pubimg">
        <br><br><br>
        <img src="Figures/dataseteyes.jpg">
      </div>
    </div>
    <div class="col-md-6">
    <div class="pub">
    <div class="pubt"> Fast and Accurate Eye Localization Algorithm for Gaze Tracking in Low Resolution Images</div>
    <hr><br>
    <div class="pubd">
      <p align = "justify"> Iris centre localization in low-resolution visible images is a challenging problem in
computer vision community due to noise, shadows, occlusions, pose variations, eye blinks, etc. This
paper proposes an efficient method for determining iris centre in low-resolution images in the visible
spectrum. Even low-cost consumer-grade webcams can be used for gaze tracking without any
additional hardware. A two-stage algorithm is proposed for iris centre localization. The proposed
method uses geometrical characteristics of the eye. In the first stage, a fast convolution based
approach is used for obtaining the coarse location of iris centre (IC). The IC location is further
refined in the second stage using boundary tracing and ellipse fitting. The algorithm has been
evaluated in public databases like BioID, Gi4E and is found to outperform the state of the art
methods. </p> </div>
    <div class="puba"> IET Computer Vision</div>
    <div class="pubv">DOI: 10.1049/iet-cvi.2015.0316 0</div>
    <div class="publ">
    <ul>
    <li><a href = "http://dx.doi.org/10.1049/iet-cvi.2015.0316">Link</a></li>
    </ul>
    </div>
      </div>
    </div>
  </div>
</div>
<br><br>

        <!-- Project One -->

        <!-- Project One -->
         <div class="pubwrap">
      <div class="row">
        <div class="col-md-6">
          <div class="pubimg">
            <br><br><br>
            <img src="Figures/cnn3.jpg">
          </div>
        </div>
        <div class="col-md-6">
        <div class="pub">
        <div class="pubt"> Real-time Eye Gaze Direction Classification Using Convolutional Neural Network</div>
        <hr><br>
        <div class="pubd">
          <p align = "justify"> Estimation eye gaze direction is useful in various
human-computer interaction tasks. Knowledge of gaze direction
can give valuable information regarding users point of attention.
Certain patterns of eye movements known as eye accessing cues
are reported to be related to the cognitive processes in the human
brain. We propose a real-time framework for the classification
of eye gaze direction and estimation of eye accessing cues. In
the first stage, the algorithm detects faces using a modified
version of the Viola-Jones algorithm. A rough eye region is
obtained using geometric relations and facial landmarks. The eye
region obtained is used in the subsequent stage to classify the
eye gaze direction. A convolutional neural network is employed
in this work for the classification of eye gaze direction. The
proposed algorithm was tested on Eye Chimera database and
found to outperform state of the art methods. The computational
complexity of the algorithm is very less in the testing phase. The
algorithm achieved an average frame rate of 24 fps in the desktop
environment. </p> </div>
        <div class="puba"> SPCOM, 2016</div>
        <div class="pubv">SPCOM, IEEE</div>
        <div class="publ">
        <ul>
        <li><a href = "http://arxiv.org/find/all/1/all:+AND+anjith+george/0/1/0/all/0/1"> arXiv Link</a></li>
        </ul>
        </div>
          </div>
        </div>
      </div>
      </div>
      <br><br>

            <!-- Project One -->


        <!------>
         <div class="pubwrap">
			<div class="row">
				<div class="col-md-6">
					<div class="pubimg">
						<br><br><br>
						<img src="Figures/eyemovement.jpg">
					</div>
				</div>
				<div class="col-md-6">
				<div class="pub">
				<div class="pubt"> A Score-level Fusion Method for Eye Movement Biometrics</div>
        <hr><br>
				<div class="pubd">
          <p align = "justify"> Eye movements contain abundant information about cognitive brain functions, neural pathways,
etc. In our approach, eye movement data is classified into fixations and saccades. Features extracted from fixations and saccades are used in a machine learning
framework for biometric authentication. A score fusion approach is adopted to classify the data
in the output layer. In the evaluation stage, the algorithm has been tested using two types of stimuli:
random dot following on a screen and text reading. The results indicate the strength of eye movement
pattern as a biometric modality. The algorithm has been evaluated on BioEye 2015 database and found
to outperform all the other methods. Eye movements are generated by a complex oculomotor plant
which is very hard to spoof by mechanical replicas. Use of eye movement dynamics along with iris
recognition technology may lead to a robust counterfeit-resistant person identification system. </p> </div>
				<div class="puba"> Pattern Recognition Letters</div>
				<div class="pubv">DOI:10.1016/j.patrec.2015.11.020</div>
				<div class="publ">
				<ul>
				<li><a href = "http://www.sciencedirect.com/science/article/pii/S0167865515004067">Link</a></li>
				</ul>
				</div>
					</div>
				</div>
			</div>
		</div>
		<br><br>
        <!-- Project One -->
         <div class="pubwrap">
			<div class="row">
				<div class="col-md-6">
					<div class="pubimg">
						<br><br><br>
						<img src="Figures/driver.png">
					</div>
				</div>
				<div class="col-md-6">
				<div class="pub">
				<div class="pubt"> A Vision Based System for Monitoring the Loss of Attention in Automotive Drivers</div>
        <hr><br>
				<div class="pubd"> <p align = "justify">On board monitoring of the alertness level of an automotive driver has been a challenging research in transportation safety and management. In this paper, we propose a robust real time embedded platform to monitor the loss of attention of the driver during day as well as night driving conditions. The PERcentage of eye CLOSure (PERCLOS) has been used as the indicator of the alertness level.  The algorithm has been cross validated using brain signals and finally been implemented on a Single Board Computer (SBC). The system is found to be robust under actual driving conditions.  </div>
			</p>	<div class="puba"> 	Intelligent Transportation Systems, IEEE Transactions on 14, no. 4 (2013): 1825-1838</div>
				<div class="pubv">DOI: 10.1109/TITS.2013.2271052</div>
				<div class="publ">
				<ul>
				<li><a href = "http://arxiv.org/find/all/1/all:+AND+anjith+george/0/1/0/all/0/1">arXiv Link</a></li>
				</ul>
				</div>
					</div>
				</div>
			</div>
		</div>


    <br><br>
        <!-- Project One -->
         <div class="pubwrap">
			<div class="row">
				<div class="col-md-6">
					<div class="pubimg">
						<br><br><br>
						<img src="Figures/expressions.png">
					</div>
				</div>
				<div class="col-md-6">
				<div class="pub">
				<div class="pubt"> A Real Time Facial Expression Classification System Using Local Binary Patterns</div>
        <hr><br>
				<div class="pubd"> <p align = "justify">Facial expression analysis is one of the popular fields
of research in human computer interaction (HCI). It has several
applications in next generation user interfaces, human emotion
analysis, behavior and cognitive modeling. In this paper, a facial
expression classification algorithm is proposed which uses Haar
classifier for face detection purpose, Local Binary Patterns(LBP)
histogram of different block sizes of a face image as feature
vectors and classifies various facial expressions using Principal
Component Analysis (PCA). The algorithm is implemented in
real time for expression classification since the computational
complexity of the algorithm is small. A customizable approach is
proposed for facial expression analysis, since the various
expressions and intensity of expressions vary from person to
person. The system uses grayscale frontal face images of a person
to classify six basic emotions namely happiness, sadness, disgust,
fear, surprise and anger. </p> </div>
				<div class="puba">IEEE Proceedings of 4 th International Conference on Intelligent Human Computer Interaction</div>
				<div class="publ">
				<ul>
				<li><a href = "http://arxiv.org/find/all/1/all:+AND+anjith+george/0/1/0/all/0/1">arXiv Link</a></li>
				</ul>
				</div>
					</div>
				</div>
			</div>
		</div>




        <br><br>
            <!-- Project One -->
             <div class="pubwrap">
    			<div class="row">
    				<div class="col-md-6">
    					<div class="pubimg">
    						<br><br><br>
    						<img src="Figures/nir.png">
    					</div>
    				</div>
    				<div class="col-md-6">
    				<div class="pub">
    				<div class="pubt"> A Video Database of Human Faces under Near Infra-Red
Illumination for Human Computer Interaction Aplications</div>
            <hr><br>
    				<div class="pubd"> <p align = "justify">Human Computer Interaction (HCI) is an evolving area
of research for coherent communication between computers and
human beings. Some of the important applications of HCI as
reported in literature are face detection, face pose estimation, face
tracking and eye gaze estimation. Development of algorithms for
these applications is an active field of research. However,
availability of standard database to validate such algorithms is
insufficient. This paper discusses the creation of such a database
created under Near Infra-Red (NIR) illumination. NIR
illumination has gained its popularity for night mode applications
since prolonged exposure to Infra-Red (IR) lighting may lead to
many health issues. The database contains NIR videos of 60
subjects in different head orientations and with different facial
expressions, facial occlusions and illumination variation. This new
database can be a very valuable resource for development and
evaluation of algorithms on face detection, eye detection, head
tracking, eye gaze tracking etc. in NIR lighting. </p> </div>
    				<div class="puba">IEEE Proceedings of 4 th International Conference on Intelligent Human Computer Interaction</div>
    				<div class="publ">
    				<ul>
    				<li><a href = "https://sites.google.com/site/nirdatabase/download">Database Download Link</a></li>
    				</ul>
    				</div>
    					</div>
    				</div>
    			</div>
    		</div>



                <br><br>
                    <!-- Project One -->
                     <div class="pubwrap">
            			<div class="row">
            				<div class="col-md-6">
            					<div class="pubimg">
            						<br><br><br>
            						<img src="Figures/fast.png">
            					</div>
            				</div>
            				<div class="col-md-6">
            				<div class="pub">
            				<div class="pubt"> A Framework for Fast Face and Eye Detection</div>
                    <hr><br>
            				<div class="pubd"> <p align = "justify">Face detection is an essential step in many computer
vision applications like surveillance, tracking, medical analysis,
facial expression analysis etc. Several approaches have been made
in the direction of face detection. Among them, Haar-like features
based method is a robust method. In spite of the robustness,
Haar - like features work with some limitations. However, with
some simple modifications in the algorithm, its performance can
be made faster and more robust. The present work refers to
the increase in speed of operation of the original algorithm by
down sampling the frames and its analysis with different scale
factors. It also discusses the detection of tilted faces using an
affine transformation of the input image. </p> </div>
            				<div class="puba">arXiv</div>
            				<div class="publ">
            				<ul>
            					<li><a href = "http://arxiv.org/find/all/1/all:+AND+anjith+george/0/1/0/all/0/1">arXiv Link</a></li>
            				</ul>
            				</div>
            					</div>
            				</div>
            			</div>
            		</div>




    <!-- /.container -->

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

</body>

</html>
